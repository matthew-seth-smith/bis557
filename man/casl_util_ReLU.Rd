% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/casl-neural-net.R
\name{casl_util_ReLU}
\alias{casl_util_ReLU}
\title{Apply a Rectified Linear Unit (ReLU) to a Vector/Matrix (from CASL)}
\usage{
casl_util_ReLU(v)
}
\arguments{
\item{v}{A numeric vector or matrix}
}
\value{
The original input with negative values truncated to zero
}
\description{
This function (from CASL) is the Rectified Linear Unit (ReLU) activator function usedfor neural networks. ReLU(x) = x if x > 0 and ReLU(x) = 0 otherwise.
}
\examples{
casl_util_ReLU(rnorm(100))
}
